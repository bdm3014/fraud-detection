{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import gc\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn import preprocessing\n",
    "\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import gc\n",
    "gc.enable()\n",
    "\n",
    "import logging\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.DEBUG)\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading the Proccessed Data from the Data Pre-Proccessing Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the 'train_12.pkl' pickle file and load it into the 'train' DataFrame\n",
    "train = pd.read_pickle('./train_12.pkl')\n",
    "\n",
    "# Read the 'test_12.pkl' pickle file and load it into the 'test' DataFrame\n",
    "test = pd.read_pickle('./test_12.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop the 'Date' Columns from dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Date columns are not indicators\n",
    "train.drop('TransactionDT', axis=1, inplace=True)\n",
    "train.drop('DT', axis=1, inplace=True)\n",
    "\n",
    "test.drop('TransactionDT', axis=1, inplace=True)\n",
    "test.drop('DT', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define Train and Test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Target variable for training set (y_train)\n",
    "y_train = train['isFraud']\n",
    "\n",
    "# Independent variables for training set (X_train)\n",
    "X_train = train.drop(['isFraud'], axis=1)\n",
    "\n",
    "# Target variable for test set (y_test)\n",
    "y_test = test['isFraud']\n",
    "\n",
    "# Independent variables for test set (X_test)\n",
    "X_test = test.drop(['isFraud'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the count of negative and positive examples\n",
    "count_negative = (y_train == 0).sum()\n",
    "count_positive = (y_train == 1).sum()\n",
    "\n",
    "# Calculate the value of scale_pos_weight\n",
    "scale_pos_weight = math.sqrt(count_negative / count_positive)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the LightGBM model woth Default Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defualt Parameter\n",
    "lgbclf = lgb.LGBMClassifier(\n",
    "  random_state=1003,\n",
    "  scale_pos_weight=scale_pos_weight,\n",
    "  metric='auc',\n",
    "  objective= 'binary',\n",
    "  device = 'gpu')\n",
    "lgbclf.fit(X_train,y_train)\n",
    "\n",
    "#prediction\n",
    "y_pred_lgbm = lgbclf.predict(X_test)\n",
    "\n",
    "# Probas for train\n",
    "y_train_lgbm_proba = lgbclf.predict_proba(X_train)[:, 1]  \n",
    "\n",
    "train_auc = roc_auc_score(y_train, y_train_lgbm_proba)\n",
    "print(f'Train AUC: {train_auc}')\n",
    "\n",
    "# Probas for test\n",
    "y_test_lgbm_proba = lgbclf.predict_proba(X_test)[:, 1]  \n",
    "test_auc = roc_auc_score(y_test, y_test_lgbm_proba)\n",
    "print(f'Test AUC: {test_auc}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hyper Parameter Optimization using Random_Search as a sklearn built in function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params={\n",
    " \"learning_rate\"    : [0.01, 0.05, 0.10, 0.15 ] ,\n",
    " \"max_depth\"        : [ 3, 6, 9, 12, 15],\n",
    " \"num_leaves\"       : [ 10, 500, 1000 ],\n",
    " \"n_estimators\"     : [ 0.1, 1, 10 , 100, 1000 ],\n",
    " \"subsample\"        : [ 0.1, 0.2, 0.3, 0.4, 0.5 , 0.7 , 0.8 , 0.9],\n",
    " \"reg_alpha\"        : [ 0.1, 0.3 , 0.6, 1 ],\n",
    " \"colsample_bytree\" : [ 0.1, 0.2, 0.3, 0.4, 0.5 , 0.7 , 0.8 , 0.9 ]\n",
    "}\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "lgbclf = lgb.LGBMClassifier()\n",
    "\n",
    "random_search=RandomizedSearchCV(\n",
    "  lgbclf,\n",
    "  param_distributions=params,\n",
    "  n_iter=10,\n",
    "  scoring='roc_auc',\n",
    "  n_jobs=-1,\n",
    "  cv=5,\n",
    "  verbose=3)\n",
    "\n",
    "random_search.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_search.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Second Model With Optimized Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbclf_1 = lgb.LGBMClassifier(\n",
    "             \n",
    "        random_state=1003,\n",
    "        scale_pos_weight=scale_pos_weight,\n",
    "        metric='auc',\n",
    "        objective= 'binary',\n",
    "        device = 'gpu',\n",
    "        subsample= 0.3,\n",
    "        reg_alpha= 0.3,\n",
    "        num_leaves=500,\n",
    "        n_estimators= 1000,\n",
    "        max_depth=9,\n",
    "        learning_rate=0.15,\n",
    "        colsample_bytree= 0.3\n",
    ")\n",
    "\n",
    "lgbclf_1.fit(X_train,y_train)\n",
    "\n",
    "#prediction\n",
    "y_pred_lgbm_1 = lgbclf_1.predict(X_test)\n",
    "\n",
    "# Probas for train\n",
    "y_train_lgbm_proba = lgbclf_1.predict_proba(X_train)[:, 1]  \n",
    "train_auc = roc_auc_score(y_train, y_train_lgbm_proba)\n",
    "print(f'Train AUC: {train_auc}')\n",
    "\n",
    "# Probas for test\n",
    "y_test_lgbm_proba = lgbclf_1.predict_proba(X_test)[:, 1]  \n",
    "test_auc = roc_auc_score(y_test, y_test_lgbm_proba)\n",
    "print(f'Test AUC: {test_auc}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using Feature Importance to Extract the most important Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Importance\n",
    "cols = list( X_train.columns)\n",
    "feature_imp = pd.DataFrame(\n",
    "  sorted(zip(lgbclf_1.feature_importances_, cols), \n",
    "         key=lambda x: x[0], \n",
    "         reverse=True), \n",
    "  columns=['Value', 'Feature'])\n",
    "feature_imp.to_clipboard()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_imp.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the top 50 important features from X_train\n",
    "selected_features = feature_imp.head(50)['Feature'].tolist()\n",
    "\n",
    "# Creating new x dataframes\n",
    "X_train_lgbm_2 = X_train[selected_features ] \n",
    "X_test_lgbm_2 = X_test[selected_features ] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracted Features which using for thr transformation for the Deployments\n",
    "X_train_lgbm_2 = X_train[['card1',\n",
    " 'TransactionAmt',\n",
    " 'card2_target_encoded',\n",
    " 'addr_target_encoded',\n",
    " 'addr1_target_encoded',\n",
    " 'dist1',\n",
    " 'D15',\n",
    " 'id_02',\n",
    " 'TransactionAmt_decimal',\n",
    " 'C1',\n",
    " 'D4',\n",
    " 'card5_target_encoded',\n",
    " 'D2',\n",
    " 'D10',\n",
    " 'D11',\n",
    " 'V307',\n",
    " 'D1',\n",
    " 'D8',\n",
    " 'D5',\n",
    " 'V310',\n",
    " 'D3',\n",
    " 'id_05',\n",
    " 'V127',\n",
    " 'id_06',\n",
    " 'V314',\n",
    " 'D9',\n",
    " 'V264',\n",
    " 'V312',\n",
    " 'id_01',\n",
    " 'D14',\n",
    " 'V203',\n",
    " 'C5',\n",
    " 'D6',\n",
    " 'V283',\n",
    " 'D12',\n",
    " 'V36',\n",
    " 'V96',\n",
    " 'V221',\n",
    " 'V62',\n",
    " 'V82',\n",
    " 'V282',\n",
    " 'V54',\n",
    " 'V76',\n",
    " 'V37',\n",
    " 'V20',\n",
    " 'V5',\n",
    " 'V44',\n",
    " 'V285',\n",
    " 'V77',\n",
    " 'V56']]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_lgbm_2 = X_test[['card1',\n",
    " 'TransactionAmt',\n",
    " 'card2_target_encoded',\n",
    " 'addr_target_encoded',\n",
    " 'addr1_target_encoded',\n",
    " 'dist1',\n",
    " 'D15',\n",
    " 'id_02',\n",
    " 'TransactionAmt_decimal',\n",
    " 'C1',\n",
    " 'D4',\n",
    " 'card5_target_encoded',\n",
    " 'D2',\n",
    " 'D10',\n",
    " 'D11',\n",
    " 'V307',\n",
    " 'D1',\n",
    " 'D8',\n",
    " 'D5',\n",
    " 'V310',\n",
    " 'D3',\n",
    " 'id_05',\n",
    " 'V127',\n",
    " 'id_06',\n",
    " 'V314',\n",
    " 'D9',\n",
    " 'V264',\n",
    " 'V312',\n",
    " 'id_01',\n",
    " 'D14',\n",
    " 'V203',\n",
    " 'C5',\n",
    " 'D6',\n",
    " 'V283',\n",
    " 'D12',\n",
    " 'V36',\n",
    " 'V96',\n",
    " 'V221',\n",
    " 'V62',\n",
    " 'V82',\n",
    " 'V282',\n",
    " 'V54',\n",
    " 'V76',\n",
    " 'V37',\n",
    " 'V20',\n",
    " 'V5',\n",
    " 'V44',\n",
    " 'V285',\n",
    " 'V77',\n",
    " 'V56']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Third Run the model with top 50 important features (We did with 100 as well. but it results to more overfitted model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbclf_2 = lgb.LGBMClassifier(\n",
    "              \n",
    "        random_state=1003,\n",
    "        scale_pos_weight=scale_pos_weight,\n",
    "        metric='auc',\n",
    "        objective= 'binary',\n",
    "        device = 'gpu',\n",
    "        subsample= 0.3,\n",
    "        reg_alpha= 0.3,\n",
    "        num_leaves=500,\n",
    "        n_estimators= 1000,\n",
    "        max_depth=9,\n",
    "        learning_rate=0.15,\n",
    "        colsample_bytree= 0.3\n",
    "    )\n",
    "\n",
    "lgbclf_2.fit(X_train_lgbm_2,y_train)\n",
    "\n",
    "#prediction\n",
    "y_pred_lgbm_3 = lgbclf_2.predict(X_test_lgbm_2)\n",
    "\n",
    "# Probas for train\n",
    "y_train_lgbm_proba = lgbclf_2.predict_proba(X_train_lgbm_2)[:, 1]  \n",
    "train_auc = roc_auc_score(y_train, y_train_lgbm_proba)\n",
    "print(f'Train AUC: {train_auc}')\n",
    "\n",
    "# Probas for test\n",
    "y_test_lgbm_proba = lgbclf_2.predict_proba(X_test_lgbm_2)[:, 1]  \n",
    "test_auc = roc_auc_score(y_test, y_test_lgbm_proba)\n",
    "print(f'Test AUC: {test_auc}')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
